{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanda\\anaconda3\\envs\\p3_6\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import scispacy\n",
    "\n",
    "from negspacy.negation import Negex\n",
    "from negspacy.termsets import termset\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzywuzzy string matching algorithm for identifying operating negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify negations_p1 in the given text\n",
    "def identify_negative_words(input_text_tokens):\n",
    "    negations = ['no', 'none', 'not', 'neither', 'nor', 'never', \"nothing\", \"nobody\", \"nowhere\"]\n",
    "    a = []\n",
    "    idx_text = []\n",
    "    negation_words = []\n",
    "    for i in range(len(negations)):\n",
    "        a.append([])\n",
    "        idx_text.append([])\n",
    "        for j in range(len(input_text_tokens)):\n",
    "            a[i].append(fuzz.ratio(negations[i], input_text_tokens[j]))\n",
    "        idx_text[i] = [idx for idx, x in enumerate(a[i]) if x==100]\n",
    "    for m in range(len(idx_text)):\n",
    "        if idx_text[m] != []:\n",
    "            [negation_words.append(input_text_tokens[t]) for t in idx_text[m]]\n",
    "    return negation_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions to identify prefix, suffix type negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify prefix_negations in the text\n",
    "def identify_prefix_neg_words(input_text_tokens):\n",
    "    prefix_negs = ['un', 'im', 'in', 'il', 'ir', 'dis', 'non', 'anti', 'de', 'counter', 'mal']\n",
    "    prefix_neg_words = []\n",
    "    idx_text = []\n",
    "    for i in range(len(prefix_negs)):\n",
    "        idx_text.append([])\n",
    "        for j in range(len(input_text_tokens)):\n",
    "            pattern = \"^%s[a-z]+$\" %prefix_negs[i]\n",
    "            blob=TextBlob(input_text_tokens[j])\n",
    "            if (re.search(pattern, input_text_tokens[j]) and blob.sentiment.polarity<0):\n",
    "                idx_text[i].append(j)\n",
    "    for m in range(len(idx_text)):\n",
    "        if idx_text[m] != []:\n",
    "            [prefix_neg_words.append(input_text_tokens[t]) for t in idx_text[m]]\n",
    "    return prefix_neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify suffix_negations in the text\n",
    "def identify_suffix_neg_words(input_text_tokens):\n",
    "    suffix_negs = ['less']\n",
    "    suffix_neg_words = []\n",
    "    idx_text = []\n",
    "    for i in range(len(suffix_negs)):\n",
    "        idx_text.append([])\n",
    "        pattern = \"^[a-z]+%s$\" %suffix_negs[i]\n",
    "        for j in range(len(input_text_tokens)):\n",
    "            blob=TextBlob(input_text_tokens[j])\n",
    "            if (re.search(pattern, input_text_tokens[j]) and blob.sentiment.polarity<=0):\n",
    "                idx_text[i].append(j)\n",
    "    for m in range(len(idx_text)):\n",
    "        if idx_text[m] != []:\n",
    "            [suffix_neg_words.append(input_text_tokens[t]) for t in idx_text[m]]\n",
    "    return suffix_neg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert \"n't\" to \"not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontract(phrase):\n",
    "    phrase = re.sub(r\"[c|C]an\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"[w|W]on\\'t\", \"will not\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not using this method anymore as converting \"n't\" to \"not\"--this is done \n",
    "def identify_punct_neg_cue(input_text_tokens):\n",
    "    idx_neg_words = []\n",
    "    neg_words = []\n",
    "    pattern = \"^n't$\"\n",
    "    for j in range(len(input_text_tokens)):\n",
    "            if re.search(pattern, input_text_tokens[j]):\n",
    "                idx_neg_words.append(j)\n",
    "                neg_words.append(input_text_tokens[j])\n",
    "    return neg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating 3 methods to identify operating, preffix, suffix type negations in one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_all_negs(text):\n",
    "    \n",
    "    tokens_text = word_tokenize(text)\n",
    "    lowercase_tokens_text = [t.lower() for t in tokens_text]\n",
    "\n",
    "    negation_words = identify_negative_words(lowercase_tokens_text)\n",
    "    prefix_negation_words = identify_prefix_neg_words(lowercase_tokens_text)\n",
    "    suffix_negation_words = identify_suffix_neg_words(lowercase_tokens_text)\n",
    "    #punct_neg_words = identify_punct_neg_cue(lowercase_tokens_text)\n",
    "#     if negation_words== [] and prefix_negation_words== [] and suffix_negation_words == [] and punct_neg_words== []: \n",
    "#         print(\"There are no negation present in the text.\")\n",
    "#     else:\n",
    "#         if negation_words != []:\n",
    "#             print(\"General negative words found in the text:\")\n",
    "#             print(*negation_words, sep = \", \")\n",
    "#         if prefix_negation_words != []:\n",
    "#             print(\"\\nPrefixed negative words found in the text:\")\n",
    "#             print(*prefix_negation_words, sep = \", \")\n",
    "#         if suffix_negation_words != []:\n",
    "#             print(\"\\nSuffixed negative words found in the text:\")\n",
    "#             print(*suffix_negation_words, sep = \", \")\n",
    "\n",
    "    all_negs = negation_words+ prefix_negation_words+ suffix_negation_words\n",
    "\n",
    "    return negation_words, prefix_negation_words, suffix_negation_words, all_negs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to test above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"To summarize... the food was incredible, nay, transcendant... but nothing brings me joy quite like the memory of the pneumatic condiment dispenser.\"\n",
    "# text = decontract(text) \n",
    "# tokens_text = word_tokenize(text)\n",
    "# lowercase_tokens_text = [t.lower() for t in tokens_text]\n",
    "# identify_negative_words(lowercase_tokens_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Enter the text: \")\n",
    "# input_text = input()\n",
    "# input_text = decontract(input_text) \n",
    "# print(\"\\n\")\n",
    "# a,b,c,d = identify_all_negs(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

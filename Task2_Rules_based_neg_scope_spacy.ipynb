{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanda\\anaconda3\\envs\\p3_6\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import scispacy\n",
    "\n",
    "from negspacy.negation import Negex\n",
    "from negspacy.termsets import termset\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from tasks_python_files.Task1_Negation_cue_detection import *\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some sentences with their scope:\n",
    "`She does not like Steve Jobs`\n",
    "scope: like Steve Jobs\n",
    "\n",
    "`There is no negation`\n",
    "scope: There is negation\n",
    "\n",
    "`Jim never likes to go to supermarket in the morning`\n",
    "scope: likes to go to market in the evening\n",
    "\n",
    "`Sam is unlikely to give his notebook to you`\n",
    "scope: Sam is to give his notebook\n",
    "\n",
    "`Sam is unlikely to give his notebook to you because he does not like you`\n",
    "scope: to give his notebook\n",
    "\n",
    "`The production has not grown, but we are hopeful for the future`\n",
    "scope: grown (one word after neg cue is affected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different rules to identify negation scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `Rule 1:` all words after the negation cue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_neg_cues(document, negation_cues):\n",
    "    indices_neg_cues=[]\n",
    "    #print(len(negation_cues))\n",
    "    for i in range(len(negation_cues)):\n",
    "        for j in range(len(document)):\n",
    "            if not indices_neg_cues.count(j):\n",
    "                if document[j].text.lower()==negation_cues[i]:\n",
    "                    indices_neg_cues.append(j)\n",
    "                    break\n",
    "    return indices_neg_cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covert_parse_tree_svg_to_png(document):\n",
    "    svg = displacy.render(document, style='dep')\n",
    "    output_path = Path(\"sentence_dep_parse_tree.svg\")\n",
    "    output_path.open(\"w\", encoding=\"utf-8\").write(svg)\n",
    "    drawing = svg2rlg(\"sentence_dep_parse_tree.svg\")\n",
    "    renderPM.drawToFile(drawing, \"sentence_dep_parse_tree.png\", fmt=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pos_tag_tree(document):\n",
    "    for token in document:\n",
    "         print(token.text, '=>',token.pos_,'=>',token.tag_)\n",
    "\n",
    "    # Load spacy's dependency tree into a networkx graph\n",
    "    edges = []\n",
    "    for token in document:\n",
    "        for child in token.children:\n",
    "            edges.append(('{0}'.format(token.lower_),\n",
    "                          '{0}'.format(child.lower_)))\n",
    "    graph = nx.Graph(edges)\n",
    "    nx.draw(graph, with_labels = True)\n",
    "    displacy.render(document, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after negation cue take remaining part of the sentence\n",
    "def get_neg_scope_rule1(cues_list, document):\n",
    "    #neg_cues = get_neg_cues_list(cues_list)\n",
    "    #print(neg_cues)\n",
    "    idx_cues_neg = get_indices_neg_cues(document,cues_list)\n",
    "    #print(idx_cues_neg)\n",
    "    neg_scope_str=\"\"\n",
    "    neg_scope_list=[]\n",
    "    for m in range(len(idx_cues_neg)):\n",
    "        neg_scope_str= neg_scope_str + (\"<\"+cues_list[m]+\"Scope>\")\n",
    "        neg_scope_list.append([])\n",
    "        for k in range(idx_cues_neg[m]+1,len(document)):\n",
    "            neg_scope_str = neg_scope_str + document[k].text\n",
    "            neg_scope_list[m].append(document[k])\n",
    "        neg_scope_str= neg_scope_str + (\"</\"+cues_list[m]+\"Scope>\")\n",
    "    return neg_scope_list, neg_scope_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rule2: after negation cue take 5 words of remaining sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after negation cue take 5 words of remaining sentence\n",
    "def get_neg_scope_rule2(cues_list, document):\n",
    "    #neg_cues = get_neg_cues_list(cues_list)\n",
    "    #print(neg_cues)\n",
    "    idx_cues_neg = get_indices_neg_cues(document,cues_list)\n",
    "    #print(idx_cues_neg)\n",
    "    neg_scope_str=\"\"\n",
    "    neg_scope_list=[]\n",
    "#     print(len(idx_cues_neg))\n",
    "#     print(idx_cues_neg)\n",
    "#     print(len(cues_list))\n",
    "#     print(cues_list)\n",
    "#     print(\"van\")\n",
    "    for m in range(len(idx_cues_neg)):\n",
    "        neg_scope_str= neg_scope_str + (\"<\"+cues_list[m]+\"Scope>\")\n",
    "        neg_scope_list.append([])\n",
    "        n_gram_count = 0\n",
    "        #print(len(document))\n",
    "        for k in range(idx_cues_neg[m]+1,len(document)):\n",
    "            #print(document[k].text)\n",
    "            if not re.match(\"^[']$\",document[k].text):\n",
    "                #print(document[k].text)\n",
    "                n_gram_count = n_gram_count + 1\n",
    "                if n_gram_count <= 5:\n",
    "                    neg_scope_str = neg_scope_str + document[k].text\n",
    "                    neg_scope_list[m].append(document[k])\n",
    "        neg_scope_str= neg_scope_str + (\"</\"+cues_list[m]+\"Scope>\")\n",
    "    return neg_scope_list, neg_scope_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rule3_a: finding sibling of neg cue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding sibling of neg cue\n",
    "#print(neg_cues)\n",
    "#rights: right child of the token\n",
    "def get_neg_scope_rule3_a(document, cues_list):\n",
    "    neg_scope_rule3_a = []\n",
    "    for i in range(len(cues_list)):\n",
    "        neg_scope_rule3_a.append([])\n",
    "        for token in document:\n",
    "            if not re.match('[0-9]|[,.-]',token.text):\n",
    "                print(token.text)\n",
    "                if token.text==cues_list[i]:\n",
    "                    neg_head = token.head\n",
    "                    #print(neg_head)\n",
    "                    neg_scope_rule3_a[i].append(neg_head)\n",
    "                    for tk in neg_head.rights:\n",
    "                        #print(tk.text)\n",
    "                        for ds in tk.subtree:\n",
    "                            neg_scope_rule3_a[i].append(ds)\n",
    "    return neg_scope_rule3_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rule3_b: finding head of neg cue and then right children of neg cue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding head of neg cue and then right children of neg cue\n",
    "#print(neg_cues)\n",
    "#rights: right child of the token\n",
    "def get_neg_scope_rule3_b(document, cues_list):\n",
    "    neg_scope_rule3_b = []\n",
    "    for i in range(len(cues_list)):\n",
    "        neg_scope_rule3_b.append([])\n",
    "        for token in document:\n",
    "            if not re.match('[0-9]|[,.-]',token.text):\n",
    "                #print(token.text)\n",
    "                if token.text==cues_list[i]:\n",
    "                    neg_head = token.head\n",
    "                    #print(neg_head)\n",
    "                    neg_scope_rule3_b[i].append(neg_head)\n",
    "                    for tk in token.rights:\n",
    "                        #print(tk.text)\n",
    "                        for ds in tk.subtree:\n",
    "                            neg_scope_rule3_b[i].append(ds)\n",
    "    return neg_scope_rule3_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rule3_final: Negation cue's head, siblings and children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_scope_rule3(document, cues_list):\n",
    "    neg_scope_rule3 = []\n",
    "    token_idx_lt = []\n",
    "    for j in range(len(cues_list)):\n",
    "        neg_scope_rule3.append([])\n",
    "        for token in document:\n",
    "            if token.text==cues_list[j] and not token_idx_lt.count(token.i):\n",
    "                token_idx_lt.append(token.i)\n",
    "                neg_head = token.head\n",
    "                #print(\"Head: \"+neg_head.text)\n",
    "                neg_scope_rule3[j].append(neg_head)\n",
    "                for tk in token.rights:\n",
    "                    #print(\"neg's children right\"+tk.text)\n",
    "                    for ds in tk.subtree:\n",
    "                        #print(\"neg token's children's children: \"+ds.text)\n",
    "                        if not re.match('[,.-]|[\\s]',ds.text):\n",
    "                            neg_scope_rule3[j].append(ds)\n",
    "                for tk in neg_head.rights:\n",
    "                    #print(\"neg's head's children: \"+tk.text)\n",
    "                    if tk.text != token.text:\n",
    "                        for ds in tk.subtree:\n",
    "                            if not re.match('[,.-]|[\\s]',ds.text):\n",
    "                                #print(\"neg's head's children's children: \"+ds.text)\n",
    "                                neg_scope_rule3[j].append(ds)\n",
    "                break\n",
    "    return neg_scope_rule3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`consider until the next verb`\n",
    "`consider adjectives adverbs after neg`\n",
    "\n",
    "`find shortest path between neg cue and next verb and that path will be the scope`\n",
    "\n",
    "`Rule 2: uses parse tree, it takes neg cue's subsequent siblings and their children. implementation: by taking the head of the token(neg_cue) and then finding siblings of the neg_cue using its head and then subtree is taken for those token which are children of neg_cue's head at right side. subtree gives us the complete tree of the token`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Along with the scope, parts of speech and named entities of the scope are retrived in this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_scope_pos_ne_rule3_new(document, cues_list):\n",
    "    neg_scope_rule3 = []\n",
    "    token_idx_lt = []\n",
    "    pos_scope = []\n",
    "    named_ents = []\n",
    "    # index of tokens which are in scope\n",
    "    scope_idx_lt = []\n",
    "\n",
    "    for e in document.ents:\n",
    "        named_ents.append(str(e) + \" (\" + e.label_ + \")\")\n",
    "\n",
    "    for j in range(len(cues_list)):\n",
    "        neg_scope_rule3.append([])\n",
    "        scope_idx_lt.append([])\n",
    "        pos_scope.append([])\n",
    "        for token in document:\n",
    "            if token.text.lower() == cues_list[j] and not token_idx_lt.count(token.i):\n",
    "                token_idx_lt.append(token.i)\n",
    "                neg_head = token.head\n",
    "                # print(token_idx_lt)\n",
    "                for ds in neg_head.subtree:\n",
    "                    # print(\"neg token's head's children: \"+ds.text)\n",
    "                    if ds.i not in scope_idx_lt[j]:\n",
    "                        if not (re.match('[-!?:;,.()]|[\\s]', ds.text)) and (ds.i != token.i):\n",
    "                            neg_scope_rule3[j].append(ds.text)\n",
    "                            scope_idx_lt[j].append(ds.i)\n",
    "                            # check neg_head noun verb or adj\n",
    "                            if ds.pos_ == 'NOUN' or ds.pos_ == 'ADJ' or ds.pos_ == 'VERB':\n",
    "                                pos_scope[j].append(ds.text + \"->\" + ds.pos_)\n",
    "                neg_scope_rule3[j] = \" \".join(cat for cat in neg_scope_rule3[j])\n",
    "                break\n",
    "\n",
    "    return neg_scope_rule3, pos_scope, named_ents, scope_idx_lt, token_idx_lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Along with the scope, parts of speech and named entities of the scope are retrived in this meth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_scope_with_neg(document, cues_list):\n",
    "    neg_scope_rule3 = []\n",
    "    token_idx_lt = []\n",
    "    named_ents = []\n",
    "    pos_scope = []\n",
    "    \n",
    "    named_ents = []\n",
    "    for e in document.ents:\n",
    "        named_ents.append(str(e) +\" (\" + e.label_ + \")\")\n",
    "\n",
    "    \n",
    "    for j in range(len(cues_list)):\n",
    "        neg_scope_rule3.append([])\n",
    "        pos_scope.append([])\n",
    "        for token in document:\n",
    "            if token.text.lower()==cues_list[j] and not token_idx_lt.count(token.i):\n",
    "                token_idx_lt.append(token.i)\n",
    "                neg_head = token.head\n",
    "               \n",
    "                for ds in neg_head.subtree:\n",
    "                    #print(\"neg token's head's children: \"+ds.text)\n",
    "                    if ds.text not in neg_scope_rule3[j]:\n",
    "                        if not (re.match('[-!?:;,.()]|[\\s]',ds.text)):\n",
    "                            neg_scope_rule3[j].append(ds.text)\n",
    "                            #check neg_head noun verb or adj\n",
    "                            if ds.pos_ =='NOUN' or ds.pos_ =='ADJ' or ds.pos_ =='VERB':\n",
    "                                pos_scope[j].append(ds.text+\"->\"+ds.pos_)                           \n",
    "                \n",
    "                neg_scope_rule3[j] = \" \".join(cat for cat in neg_scope_rule3[j])\n",
    "\n",
    "                break\n",
    "                \n",
    "    return neg_scope_rule3, pos_scope, named_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to text above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "#              \"I do not think the instructions provided were helpful\",  \n",
    "#              \"Though I did not use a guest room here, my colleagues who did shared that...\",\n",
    "#              \"The room was clean including details, I'm talking no dust,no hair in bathroom-shower or beds which I tend to find in other hotels.\",\n",
    "#              \"King bed in too small space so that one side did not even have a lamp.\",\n",
    "#              \"Our room this time was disappointing.\",\n",
    "#              \"I didn't like him \",\n",
    "#              'She does not like Steve Jobs and number 2.', \n",
    "#              'There is no negation', \n",
    "#              'Jim never likes to go to supermarket in the morning', \n",
    "#              'Sam is unlikely to give his notebook to you',\n",
    "#              'Sam is unlikely to give his notebook to you because he does not like you', \n",
    "#              'The production has not grown, but we are hopeful for the future'\n",
    "#             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #commenting for .py file\n",
    "\n",
    "\n",
    "# for sentence in sentences:\n",
    "#     print(\"Sentence is: \")\n",
    "#     print(sentence)\n",
    "#     sentence = decontract(sentence) \n",
    "#     print(\"\\n\")\n",
    "#     neg_cue_list = identify_all_negs(negations_p1, prefix_negations, suffix_negations, sentence)\n",
    "\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "#     doc = nlp(sentence)\n",
    "    \n",
    "# # #     neg_scope_list, neg_scope_string = get_neg_scope_rule1(neg_cues,doc)\n",
    "# # #     print(\"\\nNegation Scope based on rule1: \")\n",
    "# # #     print(neg_scope_list)\n",
    "# # #     print(neg_scope_string)\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     display_pos_tag_tree(doc)\n",
    "    \n",
    "# # #     print(\"Negation Scope based on rule2: \")\n",
    "# # #     print(get_neg_scope_rule2(neg_cues, doc))\n",
    "# # #     print(\"\\n\")\n",
    "    \n",
    "#     print(\"Negation Scope based on rule3: \")\n",
    "#     print(get_neg_scope_rule3(doc, neg_cues))\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "# #     print(\"Negation Scope based on rule3_new: \")\n",
    "# #     print(get_neg_scope_rule3_new(doc, neg_cues))\n",
    "# #     print(\"\\n\")\n",
    "    \n",
    "# # #     print(\"Negation Scope based on rule3_a: \")\n",
    "# # #     print(get_neg_scope_rule3_a(doc, neg_cues))\n",
    "# # #     print(\"\\n\")\n",
    "    \n",
    "# # #     print(\"Negation Scope based on rule3_b: \")\n",
    "# # #     print(get_neg_scope_rule3_b(doc, neg_cues))\n",
    "# # #     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"He hadn't done any homework, neither had he brought any of his books to class.\"\n",
    "# sentence = decontract(sentence) \n",
    "# operating_negs, prefix_negs, suffix_negs, all_negs = identify_all_negs(sentence)\n",
    "\n",
    "# print(all_negs)\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(sentence)\n",
    "\n",
    "# print(\"Negation Scope based on rule3_new: \")\n",
    "# neg_scope, p, ne, scope_idx_list, token_idx_lt = get_neg_scope_pos_ne_rule3_new(doc, all_negs)\n",
    "\n",
    "# print(neg_scope)\n",
    "# print(\"\\n\")\n",
    "\n",
    "# display_pos_tag_tree(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

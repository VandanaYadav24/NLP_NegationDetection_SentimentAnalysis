{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanda\\anaconda3\\envs\\p3_6\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from tasks_python_files.Task1_Negation_cue_detection import *\n",
    "from tasks_python_files.Task2_Rules_based_neg_scope_spacy import *\n",
    "from tasks_python_files.Task3_NegEx_method import *\n",
    "from tasks_python_files.SubTask1_From_csv_get_review_text_in_txt_file import write_reviews_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "from negspacy.negation import Negex\n",
    "from negspacy.termsets import termset\n",
    "\n",
    "import networkx as nx\n",
    "from textblob import TextBlob\n",
    "\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare negation scope and expected negation scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "df = pd.read_csv(\"./datasets/synthetic_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>ExpectedNegationCues</th>\n",
       "      <th>ExpectedNegationScope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>He hadn't done any homework, neither had he br...</td>\n",
       "      <td>neither</td>\n",
       "      <td>had he brought any of his books to class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>We didn't get to see the castle, nor did we se...</td>\n",
       "      <td>not</td>\n",
       "      <td>We did get to see the castle nor did we see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>We didn't get to see the castle, nor did we se...</td>\n",
       "      <td>nor</td>\n",
       "      <td>nor did we see the cathedral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>There is not a deal good enough that would dra...</td>\n",
       "      <td>not</td>\n",
       "      <td>There is a deal good enough that would drag me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>I am disappointed that this is not more toddle...</td>\n",
       "      <td>not</td>\n",
       "      <td>that this is more toddler friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>I am disappointed that this is not more toddle...</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I am that this is not more toddler friendly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences ExpectedNegationCues  \\\n",
       "47  He hadn't done any homework, neither had he br...              neither   \n",
       "48  We didn't get to see the castle, nor did we se...                  not   \n",
       "49  We didn't get to see the castle, nor did we se...                  nor   \n",
       "50  There is not a deal good enough that would dra...                  not   \n",
       "51  I am disappointed that this is not more toddle...                  not   \n",
       "52  I am disappointed that this is not more toddle...         disappointed   \n",
       "\n",
       "                                ExpectedNegationScope  \n",
       "47           had he brought any of his books to class  \n",
       "48  We did get to see the castle nor did we see th...  \n",
       "49                       nor did we see the cathedral  \n",
       "50  There is a deal good enough that would drag me...  \n",
       "51                 that this is more toddler friendly  \n",
       "52        I am that this is not more toddler friendly  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get neg scope for all sentences in synthetic dataset\n",
    "neg_scopes_lt = []\n",
    "neg_cues_lt = []\n",
    "temp = \"\"\n",
    "for j in range(len(df[\"Sentences\"])):\n",
    "    if df[\"Sentences\"][j] != temp:\n",
    "        sent = decontract(df[\"Sentences\"][j])\n",
    "        operating_negs, prefix_negs, suffix_negs, all_negs = identify_all_negs(sent)\n",
    "        neg_cues_lt.append(all_negs)\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc = nlp(sent)\n",
    "        neg_scope_new, pos_lt, ne, scope_idx_l, token_idx_lt = get_neg_scope_pos_ne_rule3_new(doc, all_negs)\n",
    "        neg_scopes_lt.append(neg_scope_new)\n",
    "        temp = df[\"Sentences\"][j]\n",
    "\n",
    "\n",
    "neg_scopes_list = []\n",
    "for i in range(len(neg_scopes_lt)):\n",
    "    for j in range(len(neg_scopes_lt[i])):\n",
    "        neg_scopes_list.append(neg_scopes_lt[i][j])\n",
    "\n",
    "df = df.assign(Negation_scope = neg_scopes_list)\n",
    "\n",
    "#ground truth of neg scopes of all sentences in synthetic dataset\n",
    "expected_neg_scopes_list = list(df[\"ExpectedNegationScope\"])\n",
    "\n",
    "#scope comparison\n",
    "predicted_list = []\n",
    "expected_list = []\n",
    "for i in range(len(expected_neg_scopes_list)):\n",
    "    if neg_scopes_list[i]==expected_neg_scopes_list[i]:\n",
    "        predicted_list.append(1)\n",
    "    else:\n",
    "        predicted_list.append(0)\n",
    "    expected_list.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>ExpectedNegationCues</th>\n",
       "      <th>ExpectedNegationScope</th>\n",
       "      <th>Negation_scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>There is not a deal good enough that would dra...</td>\n",
       "      <td>not</td>\n",
       "      <td>There is a deal good enough that would drag me...</td>\n",
       "      <td>There is a deal good enough that would drag me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>I am disappointed that this is not more toddle...</td>\n",
       "      <td>not</td>\n",
       "      <td>that this is more toddler friendly</td>\n",
       "      <td>that this is more toddler friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>I am disappointed that this is not more toddle...</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I am that this is not more toddler friendly</td>\n",
       "      <td>I am that this is not more toddler friendly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences ExpectedNegationCues  \\\n",
       "50  There is not a deal good enough that would dra...                  not   \n",
       "51  I am disappointed that this is not more toddle...                  not   \n",
       "52  I am disappointed that this is not more toddle...         disappointed   \n",
       "\n",
       "                                ExpectedNegationScope  \\\n",
       "50  There is a deal good enough that would drag me...   \n",
       "51                 that this is more toddler friendly   \n",
       "52        I am that this is not more toddler friendly   \n",
       "\n",
       "                                       Negation_scope  \n",
       "50  There is a deal good enough that would drag me...  \n",
       "51                 that this is more toddler friendly  \n",
       "52        I am that this is not more toddler friendly  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./datasets/Synthetic_dataset_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_l = [neg_cues_lt[i] for i in range(len(neg_cues_lt))]\n",
    "predicted_list.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6037735849056604\n"
     ]
    }
   ],
   "source": [
    "#precision_score(y_true, y_pred, average='macro')\n",
    "#micro: Calculates metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "#precision_score(expected_neg_scopes_list, neg_scopes_list, average='micro')\n",
    "#print(precision_score(expected_list, predicted_list, average='micro'))\n",
    "\n",
    "print(accuracy_score(expected_list, predicted_list))\n",
    "#recall_score(expected_list, predicted_list, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if neg_scopes_list[i]<=expected_neg_scopes_list[i]:\n",
    "        predicted_list.append(1)\n",
    "if we consider this condition then accuracy is 72 percent"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The precision is the ratio tp / (tp + fp)\n",
    "#The recall is the ratio tp / (tp + fn) \n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 'Sentences' column into list\n",
    "a = list(df['Sentences'])\n",
    "\n",
    "write_reviews_text(a,\"synthetic_dataset_txt_file.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
